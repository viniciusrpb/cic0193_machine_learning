{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cap9_1_basicscnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOB4vFUouVAht4urIo1MNzx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusrpb/cic0193_machinelearning/blob/main/cap9_1_basicscnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xl3BJYQ_5HV",
        "outputId": "c504d0d2-cc10-444b-bd7b-c1f5bd95a4a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sko_fRbqI4ap"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,GlobalMaxPool2D,Activation,Conv2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s3MtjUD_58Q"
      },
      "source": [
        "##Jargões\n",
        "\n",
        "- Stride: pulo da evolução no processo de convolução entre uma imagem e um fitlro. O ideal é utilizarmos stride 1 ou 2 (caso a imagem seja grande). No stride 1, cada pixel da imagem é considerado na convolução, enquanto que no stride 2, o filtro é passado sobre a imagem a cada 2 pixels.\n",
        "\n",
        "   Stride horizontal\n",
        "   Stride vertical\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whvCeVL6IvDr"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/leafs\" \"leafs\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pze7VJhMwvE",
        "outputId": "15cc4b15-8f37-43a8-9388-dd65f2b51603"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255.,validation_split=0.2)\n",
        "\n",
        "train_set = datagen.flow_from_directory('leafs',\n",
        "                                        batch_size=32,\n",
        "                                        class_mode='categorical',\n",
        "                                        target_size=(64,64),\n",
        "                                        subset='training')\n",
        "\n",
        "validation_set = datagen.flow_from_directory('leafs',\n",
        "                                        batch_size=32,\n",
        "                                        class_mode='categorical',\n",
        "                                        target_size=(64,64),\n",
        "                                        subset='validation')\n",
        "\n",
        "# test_set vou ficar devendo"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 240 images belonging to 4 classes.\n",
            "Found 60 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGMwj8XfEgb3"
      },
      "source": [
        "number_filters = 5\n",
        "kernel_dimensions = (5,5)\n",
        "tam_strides = (1,1)\n",
        "number_of_neurons = 10\n",
        "num_classes = 4\n",
        "\n",
        "depth = 3"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F8Sfh4xD8c6"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=number_filters,kernel_size=kernel_dimensions,strides=tam_strides, padding='same',kernel_initializer='glorot_normal',activation='relu',input_shape=(64,64,depth)))\n",
        "\n",
        "model.add(GlobalMaxPool2D())\n",
        "# fullly connected faz o stretch do activation map 2d para um vetor\n",
        "model.add(Dense(number_of_neurons))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j0w6-ScSKPe"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9NwCN40Saol",
        "outputId": "cfa83951-61a7-417c-a66a-c3413a650d45"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 64, 64, 5)         380       \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d (Global (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 44        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 484\n",
            "Trainable params: 484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzJqrABxSigg"
      },
      "source": [
        "sgd = SGD(learning_rate=0.1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPxBRdttTOWd",
        "outputId": "1907bfb8-c47d-4555-d57d-fd1eb48f5001"
      },
      "source": [
        "model.fit(train_set,validation_data=validation_set,epochs=10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 48s 2s/step - loss: 1.4305 - accuracy: 0.2167 - val_loss: 1.3882 - val_accuracy: 0.2500\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.3950 - accuracy: 0.2375 - val_loss: 1.3865 - val_accuracy: 0.2500\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.3894 - accuracy: 0.2500 - val_loss: 1.3864 - val_accuracy: 0.2833\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 19s 3s/step - loss: 1.3920 - accuracy: 0.2208 - val_loss: 1.3868 - val_accuracy: 0.2500\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.3867 - accuracy: 0.2583 - val_loss: 1.3840 - val_accuracy: 0.2500\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.3860 - accuracy: 0.2083 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.3827 - accuracy: 0.2750 - val_loss: 1.3803 - val_accuracy: 0.2833\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 17s 2s/step - loss: 1.3804 - accuracy: 0.3042 - val_loss: 1.3783 - val_accuracy: 0.2167\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.3768 - accuracy: 0.3292 - val_loss: 1.3752 - val_accuracy: 0.2500\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.3747 - accuracy: 0.2667 - val_loss: 1.3735 - val_accuracy: 0.4000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd00a286d10>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}