{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cap9_2_first_cnns.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRRgmWs6SR9OkgtwC1MP8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusrpb/cic0193_machinelearning/blob/main/cap9_2_first_cnns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh0ZWibZtXyZ"
      },
      "source": [
        "# Capítulo 9\n",
        "\n",
        "### 9.2. Criando Redes Neurais Convolucionais\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sko_fRbqI4ap"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,MaxPooling2D,Activation,Flatten,Conv2D,BatchNormalization,Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FctMSCS4wxqu"
      },
      "source": [
        "Carregando o conjunto de dados de folhas que utilizaremos como exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whvCeVL6IvDr"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s3MtjUD_58Q"
      },
      "source": [
        "### 9.2.2. Utilizando nossos próprios dados\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APEjn_A6Bton",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8e315a-73f5-4c52-e5d1-d4363f481395"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf12eShWBsI4"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/leafs\" \"leafs\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pze7VJhMwvE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8285b10-6aa1-444d-805a-efa3f210f42f"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                                   rotation_range =20,\n",
        "                                   fill_mode='nearest',\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip=True,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(\"leafs/train\",\n",
        "                                              subset='training',\n",
        "                                              target_size=(128,128),\n",
        "                                              class_mode=\"categorical\",\n",
        "                                              batch_size=32)\n",
        "\n",
        "validation_set = train_datagen.flow_from_directory(\"leafs/train\",\n",
        "                                              subset='validation',\n",
        "                                              target_size=(128,128),\n",
        "                                              class_mode=\"categorical\",\n",
        "                                              batch_size=32)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\"leafs/test\",\n",
        "                                            target_size=(128,128),\n",
        "                                            class_mode=\"categorical\",\n",
        "                                            batch_size=32)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 160 images belonging to 4 classes.\n",
            "Found 40 images belonging to 4 classes.\n",
            "Found 100 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGMwj8XfEgb3"
      },
      "source": [
        "kernel_dimensions = (5,5)\n",
        "tam_strides = (1,1)\n",
        "number_filters = 50\n",
        "number_of_neurons = 30\n",
        "\n",
        "num_classes = 4"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F8Sfh4xD8c6"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=number_filters,padding=\"same\",kernel_size=kernel_dimensions,input_shape=(128,128,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Conv2D(filters=25,padding=\"same\",kernel_size=kernel_dimensions))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Conv2D(filters=15,padding=\"same\",kernel_size=kernel_dimensions))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(number_of_neurons))\n",
        "model.add(Activation(\"relu\"))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(\"softmax\"))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEzt4ZLQSP9M",
        "outputId": "f111a8f5-268f-40f6-93bd-88a2cd53a3a1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 128, 128, 50)      3800      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 128, 128, 50)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 50)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 64, 64, 25)        31275     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 64, 64, 25)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 25)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 15)        9390      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 15)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 15)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3840)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30)                115230    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 124       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 159,819\n",
            "Trainable params: 159,819\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzJqrABxSigg"
      },
      "source": [
        "sgd = SGD(learning_rate=0.1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPxBRdttTOWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723666d8-be34-4567-9eee-692abd9a7358"
      },
      "source": [
        "model.fit(train_set,validation_data=validation_set,epochs=20)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "5/5 [==============================] - 16s 3s/step - loss: 1.4417 - accuracy: 0.2062 - val_loss: 1.3864 - val_accuracy: 0.3000\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3890 - accuracy: 0.2375 - val_loss: 1.3867 - val_accuracy: 0.2250\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3955 - accuracy: 0.2125 - val_loss: 1.3852 - val_accuracy: 0.2250\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3873 - accuracy: 0.2438 - val_loss: 1.3849 - val_accuracy: 0.3500\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3868 - accuracy: 0.2625 - val_loss: 1.3836 - val_accuracy: 0.3750\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3858 - accuracy: 0.2125 - val_loss: 1.3840 - val_accuracy: 0.2750\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3852 - accuracy: 0.2438 - val_loss: 1.3788 - val_accuracy: 0.3250\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3887 - accuracy: 0.2500 - val_loss: 1.3852 - val_accuracy: 0.2500\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3880 - accuracy: 0.2500 - val_loss: 1.3858 - val_accuracy: 0.2750\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3877 - accuracy: 0.2438 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3854 - accuracy: 0.2688 - val_loss: 1.3815 - val_accuracy: 0.3000\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3841 - accuracy: 0.2313 - val_loss: 1.3777 - val_accuracy: 0.3000\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3726 - accuracy: 0.2875 - val_loss: 1.3711 - val_accuracy: 0.2750\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3868 - accuracy: 0.2375 - val_loss: 1.3804 - val_accuracy: 0.3000\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3883 - accuracy: 0.2812 - val_loss: 1.3711 - val_accuracy: 0.2500\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3698 - accuracy: 0.3625 - val_loss: 1.3929 - val_accuracy: 0.3000\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3822 - accuracy: 0.2313 - val_loss: 1.3894 - val_accuracy: 0.2000\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3908 - accuracy: 0.2625 - val_loss: 1.3855 - val_accuracy: 0.3250\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3864 - accuracy: 0.2750 - val_loss: 1.3824 - val_accuracy: 0.3250\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 13s 3s/step - loss: 1.3857 - accuracy: 0.2375 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feefce51c10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pPWRN0lbwdW",
        "outputId": "2c2beb82-99b7-45a1-fae3-5817eb124c57"
      },
      "source": [
        "y_prob = model.predict(test_set)\n",
        "y_pred = np.argmax(y_prob,axis=1)\n",
        "\n",
        "print(classification_report(test_set.classes,y_pred))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        25\n",
            "           1       0.24      0.88      0.38        25\n",
            "           2       0.50      0.08      0.14        25\n",
            "           3       0.33      0.08      0.13        25\n",
            "\n",
            "    accuracy                           0.26       100\n",
            "   macro avg       0.27      0.26      0.16       100\n",
            "weighted avg       0.27      0.26      0.16       100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-8gdjTbBegx"
      },
      "source": [
        "## Jargões\n",
        "\n",
        "Stride: pulo da evolução no processo de convolução entre uma imagem e um fitlro. O ideal é utilizarmos stride 1 ou 2 (caso a imagem seja grande). No stride 1, cada pixel da imagem é considerado na convolução, enquanto que no stride 2, o filtro é passado sobre a imagem a cada 2 pixels.\n",
        "\n",
        "Stride horizontal Stride vertical"
      ]
    }
  ]
}